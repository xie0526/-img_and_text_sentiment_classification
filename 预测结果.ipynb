{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 3200\n",
      "Validation set size: 800\n",
      "Sample guid: 4836\n",
      "Sample labels: 0\n",
      "Text tokens: tensor([ 101, 4982, 1037, 3940, 1004, 2954, 1001, 4111, 7875, 8557,  102,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0])\n",
      "Image shape: torch.Size([3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "# 设置文件路径\n",
    "data_dir = r'/root/多模态/实验五/实验五数据'  # 该目录包含train.txt和test_without_label.txt\n",
    "txt_dir = os.path.join(data_dir, 'data')  # 文本和图像文件都在data目录下\n",
    "img_dir = txt_dir  # 图像文件也在同一目录下\n",
    "\n",
    "train_file = os.path.join(data_dir, 'train.txt')  # 训练数据标注文件\n",
    "test_file = os.path.join(data_dir, 'test_without_label.txt')  # 测试数据文件\n",
    "\n",
    "def load_labels(train_file):\n",
    "    labels = []\n",
    "    guids = []\n",
    "    with open(train_file, 'r') as f:\n",
    "        next(f)  # 跳过第一行（标题行）\n",
    "        for line in f:\n",
    "            guid, label = line.strip().split(',')\n",
    "            guids.append(guid)\n",
    "            labels.append(label)\n",
    "    return guids, labels\n",
    "\n",
    "\n",
    "# 预加载所有文本数据\n",
    "def load_all_texts(txt_dir, guids):\n",
    "    text_dict = {}\n",
    "    for guid in guids:\n",
    "        text_dict[guid] = load_text(guid, txt_dir)\n",
    "    return text_dict\n",
    "\n",
    "# 加载文本数据\n",
    "def load_text(guid, txt_dir):\n",
    "    txt_path = os.path.join(txt_dir, f'{guid}.txt')\n",
    "    \n",
    "    try:\n",
    "        with open(txt_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            text = file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Text file not found: {txt_path}\")\n",
    "        text = \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {txt_path}: {str(e)}\")\n",
    "        text = \"\"\n",
    "    \n",
    "    return text\n",
    "\n",
    "# 加载图像数据\n",
    "def load_image(guid, img_dir):\n",
    "    img_path = os.path.join(img_dir, f'{guid}.jpg')\n",
    "    \n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"Image file not found: {img_path}\")\n",
    "        return None  # 图像文件缺失\n",
    "    \n",
    "    image = Image.open(img_path).convert('RGB')  # 确保图像是RGB格式\n",
    "    return image\n",
    "\n",
    "# 创建自定义的Dataset\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, txt_dir, img_dir, guids, labels, tokenizer, transform=None):\n",
    "        self.txt_dir = txt_dir\n",
    "        self.img_dir = img_dir\n",
    "        self.gids = guids\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "        self.text_data = load_all_texts(txt_dir, guids)  # 预加载文本\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gids)\n",
    "\n",
    "    def label_to_int(self, label):\n",
    "        \"\"\"将情感标签转换为整数\"\"\"\n",
    "        if label == 'positive':\n",
    "            return 2\n",
    "        elif label == 'neutral':\n",
    "            return 1\n",
    "        elif label == 'negative':\n",
    "            return 0\n",
    "        elif label == 'null':\n",
    "            return -1\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown label: {label}\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        guid = self.gids[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # 获取文本数据\n",
    "        text = load_text(guid, self.txt_dir)\n",
    "        if text is None:\n",
    "            print(f\"Warning: No text found for {guid}\")\n",
    "        \n",
    "        # 获取图像数据\n",
    "        image = load_image(guid, self.img_dir)\n",
    "        if image is None:\n",
    "            print(f\"Warning: No image found for {guid}\")\n",
    "        \n",
    "        # 文本处理（分词和编码）\n",
    "        inputs = self.tokenizer(text, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "        \n",
    "        if self.transform and image is not None:\n",
    "            image = self.transform(image)  # 图像预处理\n",
    "        \n",
    "        label_int = self.label_to_int(label)\n",
    "        \n",
    "        # 如果图像缺失，则填充一个零张量\n",
    "        if image is None:\n",
    "            image = torch.zeros(3, 224, 224)  # 用零填充（可以根据实际需求调整）\n",
    "        \n",
    "        return {\n",
    "            'guid': guid,\n",
    "            'input_ids': inputs['input_ids'].squeeze(0),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0),\n",
    "            'image': image,\n",
    "            'label': label_int\n",
    "        }\n",
    "\n",
    "# 配置BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(r'/root/多模态/实验五/实验五数据/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594')\n",
    "\n",
    "# 定义图像预处理（包括数据增强）\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # 随机水平翻转\n",
    "    transforms.RandomResizedCrop(224),  # 随机裁剪并调整为224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 读取训练集标签和guid\n",
    "guids, labels = load_labels(train_file)\n",
    "\n",
    "# 将数据分为训练集和验证集（80%训练，20%验证）\n",
    "train_guids, val_guids, train_labels, val_labels = train_test_split(guids, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 输出划分情况\n",
    "print(f\"Training set size: {len(train_guids)}\")\n",
    "print(f\"Validation set size: {len(val_guids)}\")\n",
    "\n",
    "# 创建训练集和验证集的Dataset实例\n",
    "train_dataset = MultimodalDataset(txt_dir, img_dir, train_guids, train_labels, tokenizer, transform=image_transform)\n",
    "val_dataset = MultimodalDataset(txt_dir, img_dir, val_guids, val_labels, tokenizer, transform=image_transform)\n",
    "\n",
    "# 示例：读取一个训练样本\n",
    "sample = train_dataset[0]\n",
    "print(f\"Sample guid: {sample['guid']}\")\n",
    "print(f\"Sample labels: {sample['label']}\")\n",
    "print(f\"Text tokens: {sample['input_ids']}\")\n",
    "print(f\"Image shape: {sample['image'].size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "from torch import nn\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, model_name=r'C:\\Users\\ThinkPad\\Desktop\\实验五\\实验五数据\\models--bert-base-uncased\\snapshots\\86b5e0934494bd15c9632b12f734a8a67f723594'):\n",
    "        super(TextEncoder, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # 通过BERT提取文本特征\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # 使用[CLS]标记的输出作为文本的特征表示\n",
    "        return outputs.pooler_output  # shape: [batch_size, hidden_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(ImageEncoder, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=pretrained)\n",
    "        # 去掉最后的全连接层，保留卷积部分\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入图像，提取特征\n",
    "        x = self.resnet(x)\n",
    "        x = self.flatten(x)\n",
    "        return x  # shape: [batch_size, feature_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多模态模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultimodalModel(nn.Module):\n",
    "    def __init__(self, text_encoder, image_encoder, hidden_size=512, num_classes=3, dropout=0.5):\n",
    "        super(MultimodalModel, self).__init__()\n",
    "        self.text_encoder = text_encoder\n",
    "        self.image_encoder = image_encoder\n",
    "        self.fc1 = nn.Linear(2048 + 768, hidden_size)  # 图像特征2048 + 文本特征768\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)  # Dropout层用于防止过拟合\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_size)  # BatchNorm层有助于训练稳定\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, image):\n",
    "        # 提取文本特征\n",
    "        text_features = self.text_encoder(input_ids, attention_mask)\n",
    "        # 提取图像特征\n",
    "        image_features = self.image_encoder(image)\n",
    "        # 融合文本和图像特征\n",
    "        fused_features = torch.cat((text_features, image_features), dim=1)  # 拼接\n",
    "        # 通过全连接层1\n",
    "        x = self.fc1(fused_features)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)  # 应用Dropout\n",
    "        x = self.batch_norm(x)  # 使用BatchNorm\n",
    "        # 通过全连接层2，得到输出\n",
    "        x = self.fc2(x)\n",
    "        return x  # 输出情感类别的logits（未经过Softmax）\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数\n",
    "def train(model, train_loader, val_loader, epochs=10, lr=1e-5, patience=3):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_val_loss = float('inf')\n",
    "    no_improvement_count = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "        \n",
    "        # 训练阶段\n",
    "        train_iter = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} Training\", unit=\"batch\")\n",
    "        \n",
    "        for batch in train_iter:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask, images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct_preds += (preds == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "        \n",
    "        # 计算训练损失和准确率\n",
    "        train_accuracy = correct_preds / total_preds\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct_preds = 0\n",
    "        val_total_preds = 0\n",
    "        \n",
    "        val_iter = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} Validation\", unit=\"batch\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_iter:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                images = batch['image'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids, attention_mask, images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                val_correct_preds += (preds == labels).sum().item()\n",
    "                val_total_preds += labels.size(0)\n",
    "        \n",
    "        val_accuracy = val_correct_preds / val_total_preds\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "        \n",
    "        # 早停策略\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            no_improvement_count = 0\n",
    "            # 保存最佳模型\n",
    "            torch.save(model.state_dict(), \"best_multimodal_model.pth\")\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "            if no_improvement_count >= patience:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "/root/miniconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/20 Training: 100%|██████████| 100/100 [00:14<00:00,  6.95batch/s]\n",
      "Epoch 1/20 Validation: 100%|██████████| 25/25 [00:01<00:00, 13.63batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 1.1364, Train Accuracy: 0.3859\n",
      "Validation Loss: 1.0409, Validation Accuracy: 0.4925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 Training: 100%|██████████| 100/100 [00:13<00:00,  7.33batch/s]\n",
      "Epoch 2/20 Validation: 100%|██████████| 25/25 [00:01<00:00, 13.93batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Train Loss: 1.0333, Train Accuracy: 0.4791\n",
      "Validation Loss: 1.0113, Validation Accuracy: 0.5275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 Training: 100%|██████████| 100/100 [00:13<00:00,  7.28batch/s]\n",
      "Epoch 3/20 Validation: 100%|██████████| 25/25 [00:02<00:00, 12.38batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Train Loss: 0.9177, Train Accuracy: 0.5984\n",
      "Validation Loss: 0.9386, Validation Accuracy: 0.6200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 Training: 100%|██████████| 100/100 [00:14<00:00,  6.88batch/s]\n",
      "Epoch 4/20 Validation: 100%|██████████| 25/25 [00:02<00:00, 10.00batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Train Loss: 0.7556, Train Accuracy: 0.7097\n",
      "Validation Loss: 0.7203, Validation Accuracy: 0.7362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 Training: 100%|██████████| 100/100 [00:14<00:00,  6.70batch/s]\n",
      "Epoch 5/20 Validation: 100%|██████████| 25/25 [00:02<00:00, 10.33batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Train Loss: 0.6062, Train Accuracy: 0.7950\n",
      "Validation Loss: 0.7868, Validation Accuracy: 0.7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 Training: 100%|██████████| 100/100 [00:14<00:00,  6.71batch/s]\n",
      "Epoch 6/20 Validation: 100%|██████████| 25/25 [00:02<00:00, 10.20batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Train Loss: 0.4855, Train Accuracy: 0.8381\n",
      "Validation Loss: 1.0293, Validation Accuracy: 0.7025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 Training: 100%|██████████| 100/100 [00:15<00:00,  6.63batch/s]\n",
      "Epoch 7/20 Validation: 100%|██████████| 25/25 [00:02<00:00,  9.37batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Train Loss: 0.3914, Train Accuracy: 0.8778\n",
      "Validation Loss: 0.8961, Validation Accuracy: 0.7075\n",
      "Early stopping!\n",
      "Total training time: 121.00 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer\n",
    "import time\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载数据集\n",
    "train_dataset = MultimodalDataset(txt_dir, img_dir, train_guids, train_labels, tokenizer, transform=image_transform)\n",
    "val_dataset = MultimodalDataset(txt_dir, img_dir, val_guids, val_labels, tokenizer, transform=image_transform)\n",
    "\n",
    "# 创建DataLoader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8)  # 增加 num_workers\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "\n",
    "# 初始化模型\n",
    "text_encoder = TextEncoder(model_name=r'/root/多模态/实验五/实验五数据/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594').to(device)\n",
    "image_encoder = ImageEncoder(pretrained=True).to(device)\n",
    "model = MultimodalModel(text_encoder=text_encoder, image_encoder=image_encoder).to(device)\n",
    "\n",
    "# 设置训练参数\n",
    "epochs = 20\n",
    "lr = 1e-5\n",
    "patience = 3\n",
    "\n",
    "# 创建优化器和学习率调度器\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# 训练前，记录开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "# 开始训练\n",
    "train(model, train_loader, val_loader, epochs=epochs, lr=lr, patience=patience)\n",
    "\n",
    "# 训练后，记录结束时间\n",
    "end_time = time.time()\n",
    "print(f\"Total training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# 保存最终模型（可选）\n",
    "torch.save(model.state_dict(), \"multimodal_model.pth\")\n",
    "\n",
    "# 训练后，保存最优模型\n",
    "torch.save(model.state_dict(), \"best_multimodal_model.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_217952/573769431.py:92: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_multimodal_model.pth\"))\n",
      "Predicting: 100%|██████████| 16/16 [00:02<00:00,  7.33batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to predictions.csv.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载数据集\n",
    "test_file = os.path.join(data_dir, 'test_without_label.txt')  # 测试数据文件\n",
    "\n",
    "# 加载测试数据的guid（没有标签）\n",
    "def load_test_guids(test_file):\n",
    "    guids = []\n",
    "    with open(test_file, 'r') as f:\n",
    "        next(f)  # 跳过第一行（标题行）\n",
    "        for line in f:\n",
    "            guid = line.strip().split(',')[0]  # 仅获取guid\n",
    "            guids.append(guid)\n",
    "    return guids\n",
    "\n",
    "test_guids = load_test_guids(test_file)\n",
    "\n",
    "class MultimodalDatasettest(Dataset):\n",
    "    def __init__(self, txt_dir, img_dir, guids, labels=None, tokenizer=None, transform=None):\n",
    "        self.txt_dir = txt_dir\n",
    "        self.img_dir = img_dir\n",
    "        self.gids = guids\n",
    "        self.labels = labels if labels is not None else []  # 如果没有标签，默认为空列表\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "        self.text_data = load_all_texts(txt_dir, guids)  # 预加载文本\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gids)\n",
    "\n",
    "    def label_to_int(self, label):\n",
    "        \"\"\"将情感标签转换为整数\"\"\"\n",
    "        if label == 'positive':\n",
    "            return 2\n",
    "        elif label == 'neutral':\n",
    "            return 1\n",
    "        elif label == 'negative':\n",
    "            return 0\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown label: {label}\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        guid = self.gids[idx]\n",
    "        \n",
    "        # 获取文本数据\n",
    "        text = load_text(guid, self.txt_dir)\n",
    "        if text is None:\n",
    "            print(f\"Warning: No text found for {guid}\")\n",
    "        \n",
    "        # 获取图像数据\n",
    "        image = load_image(guid, self.img_dir)\n",
    "        if image is None:\n",
    "            print(f\"Warning: No image found for {guid}\")\n",
    "        \n",
    "        # 文本处理（分词和编码）\n",
    "        inputs = self.tokenizer(text, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "        \n",
    "        if self.transform and image is not None:\n",
    "            image = self.transform(image)  # 图像预处理\n",
    "        \n",
    "        # 如果是测试集，返回默认的标签（此处使用0作为默认标签）\n",
    "        if len(self.labels) > 0:\n",
    "            label_int = self.label_to_int(self.labels[idx])\n",
    "        else:\n",
    "            label_int = -1  # 用-1表示测试集没有标签\n",
    "        \n",
    "        # 如果图像缺失，则填充一个零张量\n",
    "        if image is None:\n",
    "            image = torch.zeros(3, 224, 224)  # 用零填充（可以根据实际需求调整）\n",
    "        \n",
    "        return {\n",
    "            'guid': guid,\n",
    "            'input_ids': inputs['input_ids'].squeeze(0),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0),\n",
    "            'image': image,\n",
    "            'label': label_int\n",
    "        }\n",
    "\n",
    "# 创建测试集的Dataset实例\n",
    "test_dataset = MultimodalDatasettest(txt_dir, img_dir, test_guids, labels=[], tokenizer=tokenizer, transform=image_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=8)\n",
    "\n",
    "# 加载最佳模型\n",
    "model = MultimodalModel(text_encoder=text_encoder, image_encoder=image_encoder).to(device)\n",
    "model.load_state_dict(torch.load(\"best_multimodal_model.pth\"))\n",
    "model.eval()  # 切换到评估模式\n",
    "\n",
    "# 预测并保存结果\n",
    "def predict(model, test_loader):\n",
    "    predictions = []\n",
    "    guids = []\n",
    "\n",
    "    # 使用tqdm进度条\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=\"Predicting\", unit=\"batch\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            images = batch['image'].to(device)\n",
    "\n",
    "            # 获取模型输出\n",
    "            outputs = model(input_ids, attention_mask, images)\n",
    "            preds = torch.argmax(outputs, dim=1)  # 获取预测类别\n",
    "\n",
    "            # 将预测结果和guid保存\n",
    "            guids.extend(batch['guid'])\n",
    "            predictions.extend(preds.cpu().numpy())  # 将结果从GPU转移到CPU\n",
    "\n",
    "    return guids, predictions\n",
    "\n",
    "\n",
    "# 执行预测\n",
    "guids, predictions = predict(model, test_loader)\n",
    "\n",
    "# 将结果保存到CSV文件\n",
    "output_df = pd.DataFrame({\n",
    "    'guid': guids,\n",
    "    'predicted_label': ['positive' if pred == 2 else 'neutral' if pred == 1 else 'negative' for pred in predictions]\n",
    "})\n",
    "\n",
    "# 保存预测结果\n",
    "output_df.to_csv(\"predictions.csv\", index=False)\n",
    "\n",
    "print(\"Predictions saved to predictions.csv.\")\n",
    "\n",
    "# 读取预测结果的CSV文件\n",
    "predictions_df = pd.read_csv('predictions.csv')\n",
    "\n",
    "# 重命名列名\n",
    "predictions_df.rename(columns={'predicted_label': 'tag'}, inplace=True)\n",
    "\n",
    "# 将数据保存为txt文件，格式为guid,tag\n",
    "predictions_df.to_csv('predictions.txt', sep=',', index=False, header=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
