{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 3200\n",
      "Validation set size: 800\n",
      "Sample guid: 4836\n",
      "Sample labels: 0\n",
      "Text tokens: tensor([ 101, 4982, 1037, 3940, 1004, 2954, 1001, 4111, 7875, 8557,  102,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0])\n",
      "Image shape: torch.Size([3, 224, 224])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import BertTokenizer\n",
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "\n",
    "# 设置文件路径\n",
    "data_dir = r'/root/多模态/实验五/实验五数据'  # 该目录包含train.txt和test_without_label.txt\n",
    "txt_dir = os.path.join(data_dir, 'data')  # 文本和图像文件都在data目录下\n",
    "img_dir = txt_dir  # 图像文件也在同一目录下\n",
    "\n",
    "train_file = os.path.join(data_dir, 'train.txt')  # 训练数据标注文件\n",
    "test_file = os.path.join(data_dir, 'test_without_label.txt')  # 测试数据文件\n",
    "\n",
    "def load_labels(train_file):\n",
    "    labels = []\n",
    "    guids = []\n",
    "    with open(train_file, 'r') as f:\n",
    "        next(f)  # 跳过第一行（标题行）\n",
    "        for line in f:\n",
    "            guid, label = line.strip().split(',')\n",
    "            guids.append(guid)\n",
    "            labels.append(label)\n",
    "    return guids, labels\n",
    "\n",
    "\n",
    "# 预加载所有文本数据\n",
    "def load_all_texts(txt_dir, guids):\n",
    "    text_dict = {}\n",
    "    for guid in guids:\n",
    "        text_dict[guid] = load_text(guid, txt_dir)\n",
    "    return text_dict\n",
    "\n",
    "# 加载文本数据\n",
    "def load_text(guid, txt_dir):\n",
    "    txt_path = os.path.join(txt_dir, f'{guid}.txt')\n",
    "    \n",
    "    try:\n",
    "        with open(txt_path, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "            text = file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Text file not found: {txt_path}\")\n",
    "        text = \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading {txt_path}: {str(e)}\")\n",
    "        text = \"\"\n",
    "    \n",
    "    return text\n",
    "\n",
    "# 加载图像数据\n",
    "def load_image(guid, img_dir):\n",
    "    img_path = os.path.join(img_dir, f'{guid}.jpg')\n",
    "    \n",
    "    if not os.path.exists(img_path):\n",
    "        print(f\"Image file not found: {img_path}\")\n",
    "        return None  # 图像文件缺失\n",
    "    \n",
    "    image = Image.open(img_path).convert('RGB')  # 确保图像是RGB格式\n",
    "    return image\n",
    "\n",
    "# 创建自定义的Dataset\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, txt_dir, img_dir, guids, labels, tokenizer, transform=None):\n",
    "        self.txt_dir = txt_dir\n",
    "        self.img_dir = img_dir\n",
    "        self.gids = guids\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "        self.text_data = load_all_texts(txt_dir, guids)  # 预加载文本\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.gids)\n",
    "\n",
    "    def label_to_int(self, label):\n",
    "        \"\"\"将情感标签转换为整数\"\"\"\n",
    "        if label == 'positive':\n",
    "            return 2\n",
    "        elif label == 'neutral':\n",
    "            return 1\n",
    "        elif label == 'negative':\n",
    "            return 0\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown label: {label}\")\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        guid = self.gids[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # 获取文本数据\n",
    "        text = load_text(guid, self.txt_dir)\n",
    "        if text is None:\n",
    "            print(f\"Warning: No text found for {guid}\")\n",
    "        \n",
    "        # 获取图像数据\n",
    "        image = load_image(guid, self.img_dir)\n",
    "        if image is None:\n",
    "            print(f\"Warning: No image found for {guid}\")\n",
    "        \n",
    "        # 文本处理（分词和编码）\n",
    "        inputs = self.tokenizer(text, padding='max_length', truncation=True, max_length=128, return_tensors=\"pt\")\n",
    "        \n",
    "        if self.transform and image is not None:\n",
    "            image = self.transform(image)  # 图像预处理\n",
    "        \n",
    "        label_int = self.label_to_int(label)\n",
    "        \n",
    "        # 如果图像缺失，则填充一个零张量\n",
    "        if image is None:\n",
    "            image = torch.zeros(3, 224, 224)  # 用零填充（可以根据实际需求调整）\n",
    "        \n",
    "        return {\n",
    "            'guid': guid,\n",
    "            'input_ids': inputs['input_ids'].squeeze(0),\n",
    "            'attention_mask': inputs['attention_mask'].squeeze(0),\n",
    "            'image': image,\n",
    "            'label': label_int\n",
    "        }\n",
    "\n",
    "# 配置BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(r'/root/多模态/实验五/实验五数据/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594')\n",
    "\n",
    "# 定义图像预处理（包括数据增强）\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),  # 随机水平翻转\n",
    "    transforms.RandomResizedCrop(224),  # 随机裁剪并调整为224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# 读取训练集标签和guid\n",
    "guids, labels = load_labels(train_file)\n",
    "\n",
    "# 将数据分为训练集和验证集（80%训练，20%验证）\n",
    "train_guids, val_guids, train_labels, val_labels = train_test_split(guids, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# 输出划分情况\n",
    "print(f\"Training set size: {len(train_guids)}\")\n",
    "print(f\"Validation set size: {len(val_guids)}\")\n",
    "\n",
    "# 创建训练集和验证集的Dataset实例\n",
    "train_dataset = MultimodalDataset(txt_dir, img_dir, train_guids, train_labels, tokenizer, transform=image_transform)\n",
    "val_dataset = MultimodalDataset(txt_dir, img_dir, val_guids, val_labels, tokenizer, transform=image_transform)\n",
    "\n",
    "# 示例：读取一个训练样本\n",
    "sample = train_dataset[0]\n",
    "print(f\"Sample guid: {sample['guid']}\")\n",
    "print(f\"Sample labels: {sample['label']}\")\n",
    "print(f\"Text tokens: {sample['input_ids']}\")\n",
    "print(f\"Image shape: {sample['image'].size()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 文本编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "from torch import nn\n",
    "\n",
    "class TextEncoder(nn.Module):\n",
    "    def __init__(self, model_name=r'C:\\Users\\ThinkPad\\Desktop\\实验五\\实验五数据\\models--bert-base-uncased\\snapshots\\86b5e0934494bd15c9632b12f734a8a67f723594'):\n",
    "        super(TextEncoder, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(model_name)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        # 通过BERT提取文本特征\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # 使用[CLS]标记的输出作为文本的特征表示\n",
    "        return outputs.pooler_output  # shape: [batch_size, hidden_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 图像编码器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "class ImageEncoder(nn.Module):\n",
    "    def __init__(self, pretrained=True):\n",
    "        super(ImageEncoder, self).__init__()\n",
    "        self.resnet = models.resnet50(pretrained=pretrained)\n",
    "        # 去掉最后的全连接层，保留卷积部分\n",
    "        self.resnet = nn.Sequential(*list(self.resnet.children())[:-1])\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 输入图像，提取特征\n",
    "        x = self.resnet(x)\n",
    "        x = self.flatten(x)\n",
    "        return x  # shape: [batch_size, feature_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多模态模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MultimodalModel(nn.Module):\n",
    "    def __init__(self, text_encoder, image_encoder, hidden_size=512, num_classes=3, dropout=0.5):\n",
    "        super(MultimodalModel, self).__init__()\n",
    "        self.text_encoder = text_encoder\n",
    "        self.image_encoder = image_encoder\n",
    "        self.fc1 = nn.Linear(2048 + 768, hidden_size)  # 图像特征2048 + 文本特征768\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout)  # Dropout层用于防止过拟合\n",
    "        self.batch_norm = nn.BatchNorm1d(hidden_size)  # BatchNorm层有助于训练稳定\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, image):\n",
    "        # 提取文本特征\n",
    "        text_features = self.text_encoder(input_ids, attention_mask)\n",
    "        # 提取图像特征\n",
    "        image_features = self.image_encoder(image)\n",
    "        # 融合文本和图像特征\n",
    "        fused_features = torch.cat((text_features, image_features), dim=1)  # 拼接\n",
    "        # 通过全连接层1\n",
    "        x = self.fc1(fused_features)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)  # 应用Dropout\n",
    "        x = self.batch_norm(x)  # 使用BatchNorm\n",
    "        # 通过全连接层2，得到输出\n",
    "        x = self.fc2(x)\n",
    "        return x  # 输出情感类别的logits（未经过Softmax）\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数\n",
    "def train(model, train_loader, val_loader, epochs=10, lr=1e-5, patience=3):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_val_loss = float('inf')\n",
    "    no_improvement_count = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "        \n",
    "        # 训练阶段\n",
    "        train_iter = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} Training\", unit=\"batch\")\n",
    "        \n",
    "        for batch in train_iter:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask, images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct_preds += (preds == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "        \n",
    "        # 计算训练损失和准确率\n",
    "        train_accuracy = correct_preds / total_preds\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct_preds = 0\n",
    "        val_total_preds = 0\n",
    "        \n",
    "        val_iter = tqdm(val_loader, desc=f\"Epoch {epoch+1}/{epochs} Validation\", unit=\"batch\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_iter:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                images = batch['image'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids, attention_mask, images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                val_correct_preds += (preds == labels).sum().item()\n",
    "                val_total_preds += labels.size(0)\n",
    "        \n",
    "        val_accuracy = val_correct_preds / val_total_preds\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "        \n",
    "        # 早停策略\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            no_improvement_count = 0\n",
    "            # 保存最佳模型\n",
    "            torch.save(model.state_dict(), \"best_multimodal_model.pth\")\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "            if no_improvement_count >= patience:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `beta` will be renamed internally to `bias`. Please use a different name to suppress this warning.\n",
      "A parameter name that contains `gamma` will be renamed internally to `weight`. Please use a different name to suppress this warning.\n",
      "/root/miniconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Epoch 1/20 Training: 100%|██████████| 100/100 [00:14<00:00,  7.12batch/s]\n",
      "Epoch 1/20 Validation: 100%|██████████| 25/25 [00:02<00:00, 11.94batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Train Loss: 1.1279, Train Accuracy: 0.3941\n",
      "Validation Loss: 1.0330, Validation Accuracy: 0.4813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 Training: 100%|██████████| 100/100 [00:14<00:00,  6.86batch/s]\n",
      "Epoch 2/20 Validation: 100%|██████████| 25/25 [00:02<00:00, 10.22batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Train Loss: 1.0601, Train Accuracy: 0.4709\n",
      "Validation Loss: 1.0053, Validation Accuracy: 0.5250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 Training: 100%|██████████| 100/100 [00:14<00:00,  6.74batch/s]\n",
      "Epoch 3/20 Validation: 100%|██████████| 25/25 [00:02<00:00, 11.60batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Train Loss: 0.9590, Train Accuracy: 0.5600\n",
      "Validation Loss: 0.7934, Validation Accuracy: 0.6763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 Training: 100%|██████████| 100/100 [00:14<00:00,  6.85batch/s]\n",
      "Epoch 4/20 Validation: 100%|██████████| 25/25 [00:01<00:00, 13.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Train Loss: 0.8227, Train Accuracy: 0.6744\n",
      "Validation Loss: 0.8818, Validation Accuracy: 0.6725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 Training: 100%|██████████| 100/100 [00:14<00:00,  6.85batch/s]\n",
      "Epoch 5/20 Validation: 100%|██████████| 25/25 [00:02<00:00, 11.25batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Train Loss: 0.7077, Train Accuracy: 0.7409\n",
      "Validation Loss: 0.7701, Validation Accuracy: 0.7037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 Training: 100%|██████████| 100/100 [00:14<00:00,  6.81batch/s]\n",
      "Epoch 6/20 Validation: 100%|██████████| 25/25 [00:02<00:00, 11.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Train Loss: 0.6138, Train Accuracy: 0.7959\n",
      "Validation Loss: 0.7695, Validation Accuracy: 0.7288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 Training: 100%|██████████| 100/100 [00:14<00:00,  6.89batch/s]\n",
      "Epoch 7/20 Validation: 100%|██████████| 25/25 [00:02<00:00, 11.66batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Train Loss: 0.4961, Train Accuracy: 0.8459\n",
      "Validation Loss: 0.7745, Validation Accuracy: 0.7050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 Training: 100%|██████████| 100/100 [00:14<00:00,  6.69batch/s]\n",
      "Epoch 8/20 Validation: 100%|██████████| 25/25 [00:01<00:00, 12.56batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Train Loss: 0.4068, Train Accuracy: 0.8734\n",
      "Validation Loss: 0.8038, Validation Accuracy: 0.7175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 Training: 100%|██████████| 100/100 [00:14<00:00,  6.81batch/s]\n",
      "Epoch 9/20 Validation: 100%|██████████| 25/25 [00:02<00:00, 10.03batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Train Loss: 0.3427, Train Accuracy: 0.8906\n",
      "Validation Loss: 0.8474, Validation Accuracy: 0.6925\n",
      "Early stopping!\n",
      "Total training time: 157.20 seconds\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer\n",
    "import time\n",
    "\n",
    "\n",
    "# 设置设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 加载数据集\n",
    "train_dataset = MultimodalDataset(txt_dir, img_dir, train_guids, train_labels, tokenizer, transform=image_transform)\n",
    "val_dataset = MultimodalDataset(txt_dir, img_dir, val_guids, val_labels, tokenizer, transform=image_transform)\n",
    "\n",
    "# 创建DataLoader\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=8)  # 增加 num_workers\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=8)\n",
    "\n",
    "# 初始化模型\n",
    "text_encoder = TextEncoder(model_name=r'/root/多模态/实验五/实验五数据/models--bert-base-uncased/snapshots/86b5e0934494bd15c9632b12f734a8a67f723594').to(device)\n",
    "image_encoder = ImageEncoder(pretrained=True).to(device)\n",
    "model = MultimodalModel(text_encoder=text_encoder, image_encoder=image_encoder).to(device)\n",
    "\n",
    "# 设置训练参数\n",
    "epochs = 20\n",
    "lr = 1e-5\n",
    "patience = 3\n",
    "\n",
    "# 创建优化器和学习率调度器\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# 训练前，记录开始时间\n",
    "start_time = time.time()\n",
    "\n",
    "# 开始训练\n",
    "train(model, train_loader, val_loader, epochs=epochs, lr=lr, patience=patience)\n",
    "\n",
    "# 训练后，记录结束时间\n",
    "end_time = time.time()\n",
    "print(f\"Total training time: {end_time - start_time:.2f} seconds\")\n",
    "\n",
    "# 保存最终模型（可选）\n",
    "torch.save(model.state_dict(), \"multimodal_model.pth\")\n",
    "\n",
    "# 训练后，保存最优模型\n",
    "torch.save(model.state_dict(), \"best_multimodal_model.pth\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "class TextOnlyModel(nn.Module):\n",
    "    def __init__(self, text_encoder, hidden_size=512, num_classes=3):\n",
    "        super(TextOnlyModel, self).__init__()\n",
    "        self.text_encoder = text_encoder\n",
    "        self.fc1 = nn.Linear(768, hidden_size)  # BERT的隐藏层大小是768\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  # 分类层\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        text_features = self.text_encoder(input_ids, attention_mask)\n",
    "        x = self.fc1(text_features)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageOnlyModel(nn.Module):\n",
    "    def __init__(self, image_encoder, hidden_size=512, num_classes=3):\n",
    "        super(ImageOnlyModel, self).__init__()\n",
    "        self.image_encoder = image_encoder\n",
    "        self.fc1 = nn.Linear(2048, hidden_size)  # ResNet50的输出特征大小是2048\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  # 分类层\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, image):\n",
    "        image_features = self.image_encoder(image)\n",
    "        x = self.fc1(image_features)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.5400, Train Accuracy: 0.8534\n",
      "Validation Loss: 0.8542, Validation Accuracy: 0.6625\n",
      "Epoch 2/10, Train Loss: 0.2029, Train Accuracy: 0.9556\n",
      "Validation Loss: 1.0022, Validation Accuracy: 0.6700\n",
      "Epoch 3/10, Train Loss: 0.1559, Train Accuracy: 0.9637\n",
      "Validation Loss: 1.0744, Validation Accuracy: 0.6963\n",
      "Epoch 4/10, Train Loss: 0.1323, Train Accuracy: 0.9681\n",
      "Validation Loss: 1.1658, Validation Accuracy: 0.6850\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "def train_text_only_model(model, train_loader, val_loader, epochs=10, lr=1e-5, patience=3):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_val_loss = float('inf')\n",
    "    no_improvement_count = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct_preds += (preds == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "        \n",
    "        train_accuracy = correct_preds / total_preds\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct_preds = 0\n",
    "        val_total_preds = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids, attention_mask)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                val_correct_preds += (preds == labels).sum().item()\n",
    "                val_total_preds += labels.size(0)\n",
    "        \n",
    "        val_accuracy = val_correct_preds / val_total_preds\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "        \n",
    "        # 早停策略\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            # 保存最佳模型\n",
    "            torch.save(model.state_dict(), \"best_text_only_model.pth\")\n",
    "            no_improvement_count = 0\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "            if no_improvement_count >= patience:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "\n",
    "    # 最终保存模型\n",
    "    torch.save(model.state_dict(), \"final_text_only_model.pth\")\n",
    "\n",
    "# 初始化文本模型\n",
    "text_only_model = TextOnlyModel(text_encoder=text_encoder).to(device)\n",
    "\n",
    "# 训练文本单模态模型\n",
    "train_text_only_model(text_only_model, train_loader, val_loader, epochs=10, lr=1e-5, patience=3)\n",
    "\n",
    "torch.save(text_only_model.state_dict(), \"final_text_only_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Train Loss: 0.7481, Train Accuracy: 0.6659\n",
      "Validation Loss: 0.7952, Validation Accuracy: 0.6512\n",
      "Epoch 2/10, Train Loss: 0.5689, Train Accuracy: 0.7578\n",
      "Validation Loss: 0.8215, Validation Accuracy: 0.6512\n",
      "Epoch 3/10, Train Loss: 0.4825, Train Accuracy: 0.8125\n",
      "Validation Loss: 0.8926, Validation Accuracy: 0.6375\n",
      "Epoch 4/10, Train Loss: 0.4372, Train Accuracy: 0.8269\n",
      "Validation Loss: 0.8674, Validation Accuracy: 0.6325\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "def train_image_only_model(model, train_loader, val_loader, epochs=10, lr=1e-5, patience=3):\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    best_val_loss = float('inf')\n",
    "    no_improvement_count = 0\n",
    "    \n",
    "    # 训练过程中使用学习率调度器\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        correct_preds = 0\n",
    "        total_preds = 0\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['label'].to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct_preds += (preds == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "        \n",
    "        train_accuracy = correct_preds / total_preds\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        \n",
    "        # 验证阶段\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        val_correct_preds = 0\n",
    "        val_total_preds = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                images = batch['image'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                val_correct_preds += (preds == labels).sum().item()\n",
    "                val_total_preds += labels.size(0)\n",
    "        \n",
    "        val_accuracy = val_correct_preds / val_total_preds\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}\")\n",
    "        print(f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "        \n",
    "        # 早停策略\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            no_improvement_count = 0\n",
    "            # 保存当前最佳模型\n",
    "            torch.save(model.state_dict(), \"best_image_only_model.pth\")\n",
    "        else:\n",
    "            no_improvement_count += 1\n",
    "            if no_improvement_count >= patience:\n",
    "                print(\"Early stopping!\")\n",
    "                break\n",
    "\n",
    "        # 更新学习率\n",
    "        scheduler.step()\n",
    "\n",
    "# 初始化图像模型\n",
    "image_only_model = ImageOnlyModel(image_encoder=image_encoder).to(device)\n",
    "\n",
    "# 训练图像单模态模型\n",
    "train_image_only_model(image_only_model, train_loader, val_loader, epochs=10, lr=1e-5, patience=3)\n",
    "\n",
    "torch.save(image_only_model.state_dict(), \"final_image_only_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    total_loss = 0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    criterion = nn.CrossEntropyLoss()  # 损失函数\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            if isinstance(model, TextOnlyModel):  # 处理文本模型\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids, attention_mask)\n",
    "            elif isinstance(model, ImageOnlyModel):  # 处理图像模型\n",
    "                images = batch['image'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = model(images)\n",
    "            elif isinstance(model, MultimodalModel):  # 处理多模态模型\n",
    "                input_ids = batch['input_ids'].to(device)\n",
    "                attention_mask = batch['attention_mask'].to(device)\n",
    "                images = batch['image'].to(device)\n",
    "                labels = batch['label'].to(device)\n",
    "                \n",
    "                outputs = model(input_ids, attention_mask, images)\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported model type: {type(model)}\")\n",
    "            \n",
    "            # 计算损失\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            # 计算预测结果\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            correct_preds += (preds == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "            \n",
    "            # 保存所有预测值和标签\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    accuracy = correct_preds / total_preds\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    \n",
    "    print(f\"Evaluation Loss: {avg_loss:.4f}, Evaluation Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # 输出分类报告\n",
    "    report = classification_report(all_labels, all_preds,zero_division=1, target_names=[\"negative\", \"neutral\", \"positive\"])\n",
    "    print(report)\n",
    "    \n",
    "    # 如果需要，返回评估结果\n",
    "    return accuracy, avg_loss, report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Text Only Model...\n",
      "Evaluation Loss: 0.8973, Evaluation Accuracy: 0.6512\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.76      0.32      0.46       234\n",
      "     neutral       0.24      0.35      0.28        83\n",
      "    positive       0.72      0.86      0.78       483\n",
      "\n",
      "    accuracy                           0.65       800\n",
      "   macro avg       0.57      0.51      0.51       800\n",
      "weighted avg       0.68      0.65      0.64       800\n",
      "\n",
      "Evaluating Image Only Model...\n",
      "Evaluation Loss: 0.8478, Evaluation Accuracy: 0.6025\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00       234\n",
      "     neutral       1.00      0.00      0.00        83\n",
      "    positive       0.60      1.00      0.75       483\n",
      "\n",
      "    accuracy                           0.60       800\n",
      "   macro avg       0.53      0.33      0.25       800\n",
      "weighted avg       0.47      0.60      0.45       800\n",
      "\n",
      "Evaluating Multimodal Model...\n",
      "Evaluation Loss: 0.8441, Evaluation Accuracy: 0.7050\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.69      0.53      0.60       234\n",
      "     neutral       0.34      0.28      0.31        83\n",
      "    positive       0.76      0.86      0.81       483\n",
      "\n",
      "    accuracy                           0.70       800\n",
      "   macro avg       0.59      0.56      0.57       800\n",
      "weighted avg       0.69      0.70      0.69       800\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.705,\n",
       " 0.8440843033790588,\n",
       " '              precision    recall  f1-score   support\\n\\n    negative       0.69      0.53      0.60       234\\n     neutral       0.34      0.28      0.31        83\\n    positive       0.76      0.86      0.81       483\\n\\n    accuracy                           0.70       800\\n   macro avg       0.59      0.56      0.57       800\\nweighted avg       0.69      0.70      0.69       800\\n')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# 加载文本单模态模型\n",
    "text_only_model.load_state_dict(torch.load(\"best_text_only_model.pth\", weights_only=True))\n",
    "image_only_model.load_state_dict(torch.load(\"best_image_only_model.pth\", weights_only=True))\n",
    "model.load_state_dict(torch.load(\"best_multimodal_model.pth\", weights_only=True))\n",
    "\n",
    "text_only_model.to(device)\n",
    "image_only_model.to(device)\n",
    "model.to(device)\n",
    "\n",
    "# 评估文本单模态模型\n",
    "print(\"Evaluating Text Only Model...\")\n",
    "evaluate(text_only_model, val_loader)  # 在验证集上评估\n",
    "\n",
    "# 评估图像单模态模型\n",
    "print(\"Evaluating Image Only Model...\")\n",
    "evaluate(image_only_model, val_loader)  # 在验证集上评估\n",
    "\n",
    "# 评估多模态模型\n",
    "print(\"Evaluating Multimodal Model...\")\n",
    "evaluate(model, val_loader)  # 在验证集上评估\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
